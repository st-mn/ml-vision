{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "KUu4vOt5zI9d"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Stan Toman\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy553YSVmYiK"
      },
      "source": [
        "Example of object detection in image using TF detection modules."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Support Functions"
      ],
      "metadata": {
        "id": "8WQKZzixAIq2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cPY9Ou4sWs_"
      },
      "outputs": [],
      "source": [
        "# Imports For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Imports For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# Imports For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "#Imports For measuring the inference time.\n",
        "import time\n",
        "\n",
        "# Check Tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n",
        "\n",
        "# Support function to display image.\n",
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "\n",
        "# Support function to download and resize image.\n",
        "def download_and_resize_image(url, new_width=256, new_height=256,\n",
        "                              display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  print(\"Image downloaded to %s.\" % filename)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename\n",
        "\n",
        "# Support function to bind frame into image.\n",
        "def draw_bounding_box_on_image(image,\n",
        "                               ymin,\n",
        "                               xmin,\n",
        "                               ymax,\n",
        "                               xmax,\n",
        "                               color,\n",
        "                               font,\n",
        "                               thickness=4,\n",
        "                               display_str_list=()):\n",
        "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  im_width, im_height = image.size\n",
        "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                                ymin * im_height, ymax * im_height)\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
        "             (left, top)],\n",
        "            width=thickness,\n",
        "            fill=color)\n",
        "\n",
        "  # If the total height of the display strings added to the top of the bounding\n",
        "  # box exceeds the top of the image, stack the strings below the bounding box\n",
        "  # instead of above.\n",
        "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
        "  # Each display_str has a top and bottom margin of 0.05x.\n",
        "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        "  if top > total_display_str_height:\n",
        "    text_bottom = top\n",
        "  else:\n",
        "    text_bottom = top + total_display_str_height\n",
        "  # Reverse list and print from bottom to top.\n",
        "  for display_str in display_str_list[::-1]:\n",
        "    text_width, text_height = font.getsize(display_str)\n",
        "    margin = np.ceil(0.05 * text_height)\n",
        "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
        "                    (left + text_width, text_bottom)],\n",
        "                   fill=color)\n",
        "    draw.text((left + margin, text_bottom - text_height - margin),\n",
        "              display_str,\n",
        "              fill=\"black\",\n",
        "              font=font)\n",
        "    text_bottom -= text_height - 2 * margin\n",
        "\n",
        "#Support function to draw into image.\n",
        "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
        "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "  colors = list(ImageColor.colormap.values())\n",
        "\n",
        "  try:\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
        "                              25)\n",
        "  except IOError:\n",
        "    print(\"Font not found, using default font.\")\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "  for i in range(min(boxes.shape[0], max_boxes)):\n",
        "    if scores[i] >= min_score:\n",
        "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
        "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
        "                                     int(100 * scores[i]))\n",
        "      color = colors[hash(class_names[i]) % len(colors)]\n",
        "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "      draw_bounding_box_on_image(\n",
        "          image_pil,\n",
        "          ymin,\n",
        "          xmin,\n",
        "          ymax,\n",
        "          xmax,\n",
        "          color,\n",
        "          font,\n",
        "          display_str_list=[display_str])\n",
        "      np.copyto(image, np.array(image_pil))\n",
        "  return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D19UCu9Q2-_8"
      },
      "source": [
        "##Test Load Image\n",
        "\n",
        "Load a public image from https://commons.wikimedia.org, save locally, and display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLWNhjUY1mhg"
      },
      "outputs": [],
      "source": [
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chinese_room_QE2_132.jpg\"  #@param\n",
        "downloaded_image_path = download_and_resize_image(image_url, 800, 600, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-VdfLbC1w51"
      },
      "source": [
        "##Test select TF detection module \n",
        "* **FasterRCNN+InceptionResNet V2**: high accuracy.\n",
        "* **ssd+mobilenet V2**: small and fast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uazJ5ASc2_QE"
      },
      "outputs": [],
      "source": [
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
        "\n",
        "detector = hub.load(module_handle).signatures['default']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test run detector and display objects"
      ],
      "metadata": {
        "id": "FoCDsLnB4Zq8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwGJV96WWBLH"
      },
      "outputs": [],
      "source": [
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img\n",
        "\n",
        "def run_detector(detector, path):\n",
        "  img = load_img(path)\n",
        "\n",
        "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  start_time = time.time()\n",
        "  result = detector(converted_img)\n",
        "  end_time = time.time()\n",
        "\n",
        "  result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "  print(\"Inference time: \", end_time-start_time)\n",
        "\n",
        "  image_with_boxes = draw_boxes(\n",
        "      img.numpy(), result[\"detection_boxes\"],\n",
        "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
        "\n",
        "  display_image(image_with_boxes)\n",
        "\n",
        "run_detector(detector, downloaded_image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deploy detector as API microservice endpoint"
      ],
      "metadata": {
        "id": "CzKxtPdLBxVh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxphMR5ExQ1v"
      },
      "source": [
        "# build requirements\n",
        "!pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a procfile\n",
        "file_name = 'Procfile'\n",
        "content = 'web: gunicorn app:app'\n",
        "\n",
        "with open(file_name, 'w') as f:\n",
        "    f.write(content)"
      ],
      "metadata": {
        "id": "VzbhZHeLUSfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_name = 'templates'\n",
        "file_name = 'index.html'\n",
        "content = '''<!DOCTYPE html>\n",
        "<html >\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <title>Infer ObjectDetection Model and pass image url</title>\n",
        "  <link href='https://fonts.googleapis.com/css?family=Pacifico' rel='stylesheet' type='text/css'>\n",
        "<link href='https://fonts.googleapis.com/css?family=Arimo' rel='stylesheet' type='text/css'>\n",
        "<link href='https://fonts.googleapis.com/css?family=Hind:300' rel='stylesheet' type='text/css'>\n",
        "<link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>\n",
        "<link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css') }}\">\n",
        "  \n",
        "</head>\n",
        "\n",
        "<body style=\"background: #000;\">\n",
        " <div class=\"login\">\n",
        "\t<h1>Insert Image URL:</h1>\n",
        "\n",
        "     <!-- Main Input For Receiving Query to our ML -->\n",
        "    <form action=\"{{ url_for('predict')}}\"method=\"post\" enctype=\"multipart/form-data\">\n",
        "      <input type=\"text\" id=\"image-url\" name=\"image-url\">\n",
        "      <button type=\"submit\" class=\"btn btn-primary btn-block btn-large\">Detect Objects</button>\n",
        "    </form>\n",
        "\n",
        "   <br>\n",
        "   <br>\n",
        "   {{ prediction_text }}\n",
        "\n",
        " </div>\n",
        "</body>\n",
        "</html>'''\n",
        "\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "\n",
        "with open(os.path.join(folder_name, file_name), 'w') as f:\n",
        "    f.write(content)"
      ],
      "metadata": {
        "id": "-JPEKI_IvWo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60NJQ6Tdpv5"
      },
      "source": [
        "# install flask and ngrok\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok\n",
        "\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# get auth token here and paste below: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "ngrok.set_auth_token(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define app.py\n",
        "import numpy as np\n",
        "from flask import Flask, request, jsonify, render_template\n",
        "import pickle\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/predict',methods=['POST','GET'])\n",
        "def predict():\n",
        "\n",
        "    downloaded_image_path = request.form.values()    \n",
        "\n",
        "    result = run_detector(detector, downloaded_image_path)\n",
        "    \n",
        "    return render_template('index.html', image_url=result)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()\n",
        "\n"
      ],
      "metadata": {
        "id": "NzddPw2_tu0_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}